{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fa190f",
   "metadata": {},
   "source": [
    "\n",
    "# Uma breve introdução ao Machine Learning\n",
    "## Problemas propostos #05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c6cb3",
   "metadata": {},
   "source": [
    "- **Dia 5**: [Adaptação de métodos lineares para problemas não lineares](https://github.com/GabrielWendell/Intro_ML/blob/main/Notebooks/Dia5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27073b3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd30d70",
   "metadata": {},
   "source": [
    "### Você vai precisar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6bde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mls import locate_data\n",
    "blobs_data = pd.read_hdf(locate_data('blobs_data.hf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3dd0e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874ff3a",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36615f4d",
   "metadata": {},
   "source": [
    "**a)** Revise este [`Notebook`]() do dia 5 sobre como adaptar métodos lineares a problemas não lineares. O principal *insight* aqui que será útil mais adiante no curso é o **truque do kernel**, que é responsável pela maior parte do poder expressivo das redes neurais. \n",
    "\n",
    "Escolha um conjunto de dados para \"adotar\". Seu conjunto de dados deve:\n",
    "\n",
    "- ser de domínio público (mesmo que ainda não esteja disponível publicamente), e\n",
    "\n",
    "- estar no formato tabular 2D padrão usado para algoritmos de ML, com colunas correspondentes a recursos e linhas a observações (amostras) e\n",
    "\n",
    "- tem um número de recursos ($D$) e amostras ($N$) que satisfazem $D\\cdot N < 1.000.000$ (portanto, corte um conjunto de dados maior, se necessário).\n",
    "\n",
    "Eu encorajo você a usar alguns dados (reais ou simulados) relacionados à sua pesquisa, mas qualquer conjunto de dados está ok."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c39ed",
   "metadata": {},
   "source": [
    "Preencha a função abaixo para carregar seu conjunto de dados em um dataframe pandas. Seu código pode ler um arquivo (eu recomendo o formato CSV ou HDF5) do seu repositório de trabalhos de casa, se for pequeno o suficiente (< 2 Mb) ou então baixar o arquivo de um URL público (alguns dos [leitores de pandas](https://pandas.pydata.org/pandas-docs/stable/reference/index.html) podem ler diretamente de um URL). Inclua todas as etapas necessárias para obter seu dataframe final no formato necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d55eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adopted_data():\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbdaa9d",
   "metadata": {},
   "source": [
    "**b)** Aplique os *sanity tests* abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5457ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_adopted_data()\n",
    "N, D = df.shape\n",
    "\n",
    "assert N * D < 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c562f9f",
   "metadata": {},
   "source": [
    "**c)** Gere um resumo de alto nível dos (primeiros 10) recursos numéricos de seus dados usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3bb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "df[numeric_features[:10]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a0e7d",
   "metadata": {},
   "source": [
    "**e)** Realize uma visualização de alto nível de seus dados usando (sinta-se à vontade para editar vars para selecionar os recursos mais informativos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b534cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = df.dropna()\n",
    "numeric_features = valid.select_dtypes(include=[np.number]).columns.tolist()\n",
    "sns.pairplot(valid.iloc[:1000], vars=numeric_features[:5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ead6f",
   "metadata": {},
   "source": [
    "**f)** Realize uma visualização de alto nível de seus dados usando (sinta-se à vontade para editar vars para selecionar os recursos mais informativos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = df.dropna()\n",
    "numeric_features = valid.select_dtypes(include=[np.number]).columns.tolist()\n",
    "sns.pairplot(valid.iloc[:1000], vars=numeric_features[:5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc00d56",
   "metadata": {},
   "source": [
    "**g)** Encontre a melhor atribuição para 3 *clusters* usando K-means (ou altere o valor de `n_clusters` abaixo para algo mais apropriado):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = df.dropna().copy()\n",
    "numeric_features = valid.select_dtypes(include=[np.number]).columns.tolist()\n",
    "fit = cluster.KMeans(n_clusters=3).fit(valid[numeric_features])\n",
    "valid['cluster'] = fit.labels_\n",
    "\n",
    "for i in range(fit.n_clusters):\n",
    "    print(f'Atribuído {np.count_nonzero(fit.labels_ == i)} / {len(valid)} samples para o cluster {i}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a936f",
   "metadata": {},
   "source": [
    "**h)** Refaça o gráfico de pares com amostras coloridas por sua atribuição de *cluster*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e566f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(valid.iloc[:1000], vars=numeric_features[:5], hue='cluster', diag_kind='hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349f920",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24788110",
   "metadata": {},
   "source": [
    "## Problema 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e040b7cd",
   "metadata": {},
   "source": [
    "**a)** Neste problema, você implementará o núcleo dos passos E e M para o método do [modelo de mistura gaussiana (GMM)](https://scikit-learn.org/stable/modules/mixture.html). Observe as semelhanças com as etapas E e M do método K-means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa80035",
   "metadata": {},
   "source": [
    "Primeiro, implemente a função abaixo para avaliar a [densidade de probabilidade gaussiana multidimensional](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) para a média arbitrária $\\overrightarrow{\\mu}$ e matriz de covariância $C$ (consulte a aula para mais detalhes sobre a notação usada aqui):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38973e04",
   "metadata": {},
   "source": [
    "$$G(\\overrightarrow{x};\\overrightarrow{\\mu},C)=(2\\pi)^{-D/2}|C|^{-1/2}\\exp{\\Bigg[-\\frac{1}{2}(\\overrightarrow{x}-\\overrightarrow{\\mu})^{T}C^{-1}(\\overrightarrow{x}-\\overrightarrow{\\mu})}\\Bigg]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495362c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_pdf(x, mu, C):\n",
    "    \"\"\"Avalie a densidade de probabilidade gaussiana.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    x : array\n",
    "        1D array de valores de recurso D para uma única amostra\n",
    "    mu : array\n",
    "        1D array de D valores médios de características para este componente.\n",
    "    C : array\n",
    "        2D array com shape (D, D) de elementos da matriz de covariância para este componente.\n",
    "        Deve ser positivo definido (e, portanto, simétrico).\n",
    "        \n",
    "    Retorna\n",
    "    -------\n",
    "    float\n",
    "        Densidade de probabilidade\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    mu = np.asarray(mu)\n",
    "    C = np.asarray(C)\n",
    "    D = len(x)\n",
    "    \n",
    "    assert x.shape == (D,) and mu.shape == (D,)\n",
    "    assert C.shape == (D, D)\n",
    "    assert np.allclose(C.T, C)\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7ab63",
   "metadata": {},
   "source": [
    "**b)** Aplique os seguintes testes de validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(Gaussian_pdf([0], [0], [[1]]), 1 / np.sqrt(2 * np.pi))\n",
    "assert np.allclose(Gaussian_pdf([1], [1], [[1]]), 1 / np.sqrt(2 * np.pi))\n",
    "assert np.allclose(Gaussian_pdf([0], [0], [[2]]), 1 / np.sqrt(4 * np.pi))\n",
    "assert np.allclose(Gaussian_pdf([1], [0], [[1]]), np.exp(-0.5) / np.sqrt(2 * np.pi))\n",
    "\n",
    "################################\n",
    "\n",
    "assert np.allclose(Gaussian_pdf([0, 0], [0, 0], [[1, 0], [0, 1]]), 1 / (2 * np.pi))\n",
    "assert np.allclose(Gaussian_pdf([1, 0], [1, 0], [[1, 0], [0, 1]]), 1 / (2 * np.pi))\n",
    "assert np.allclose(Gaussian_pdf([1, -1], [1, -1], [[1, 0], [0, 1]]), 1 / (2 * np.pi))\n",
    "assert np.allclose(Gaussian_pdf([1, 0], [1, 0], [[4, 0], [0, 1]]), 1 / (4 * np.pi))\n",
    "\n",
    "################################\n",
    "\n",
    "assert np.round(Gaussian_pdf([0, 0], [1, 0], [[4, +1], [+1, 1]]), 5) == 0.07778\n",
    "assert np.round(Gaussian_pdf([0, 0], [1, 0], [[4, -1], [-1, 1]]), 5) == 0.07778\n",
    "assert np.round(np.log(Gaussian_pdf([1, 0, -1], [1, 2, 3], [[4, -1, 0], [-1, 1, 0], [0, 0, 2]])), 5) == -10.31936"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5316e287",
   "metadata": {},
   "source": [
    "**c)** Em seguida, implemente o E-step na função abaixo. Isso consiste em calcular a probabilidade relativa de que cada amostra $x_{n}$ ($n$-ésima linha de $X$) pertença a cada componente $k$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73ebd2",
   "metadata": {},
   "source": [
    "$$p_{nk}=\\frac{\\omega_{k}G(\\overrightarrow{x}_{n};\\overrightarrow{\\mu}_{k},C_{k})}{\\sum_{j=1}^{K}\\omega_{j}G(\\overrightarrow{x}_{n};\\overrightarrow{\\mu}_{j},C_{j})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12fd85d",
   "metadata": {},
   "source": [
    "Observe que essas probabilidades relativas (também chamadas de *responsabilidades*) somam um sobre os componentes $k$ para cada amostra $n$. Observe também que consideramos os parâmetros $(\\omega_{k},\\overrightarrow{\\mu}_{k},C_{k})$ de cada componente fixados durante esta etapa. \n",
    "\n",
    "- **Dica**: use sua função *Gaussian_pdf* aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc03147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(X, w, mu, C):\n",
    "    \"\"\"Executa uma etapa E do GMM.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    X : array com shape (N, D)\n",
    "        Dados de entrada consistindo de N amostras em D dimensões.\n",
    "    w : array com shape (K,)\n",
    "        Pesos por componente.\n",
    "    mu : array com shape (K, D)\n",
    "        Matriz de vetores médios para cada componente.\n",
    "    C : array com shape (K, D, D).\n",
    "        Matriz de matrizes de covariância para cada componente.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    array com shape (K, N)\n",
    "        Matriz de probabilidades relativas a que cada amostra pertence\n",
    "        cada componente, normalizado para que as probabilidades por componente\n",
    "        para cada soma de amostra para um.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    K = len(w)\n",
    "    \n",
    "    assert w.shape == (K,)\n",
    "    assert mu.shape == (K, D)\n",
    "    assert C.shape == (K, D, D)\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f7706",
   "metadata": {},
   "source": [
    "**d)** Execute os testes abaixo para verificar a validade do seu código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-1, 1, 5).reshape(-1, 1)\n",
    "w = np.full(4, 0.25)\n",
    "mu = np.array([[-2], [-1], [0], [1]])\n",
    "C = np.ones((4, 1, 1))\n",
    "\n",
    "# print(repr(np.round(E_step(X, w, mu, C), 3)))\n",
    "assert np.all(\n",
    "    np.round(E_step(X, w, mu, C), 3) ==\n",
    "    [[ 0.258,  0.134,  0.058,  0.021,  0.006],\n",
    "     [ 0.426,  0.366,  0.258,  0.152,  0.077],\n",
    "     [ 0.258,  0.366,  0.426,  0.414,  0.346],\n",
    "     [ 0.058,  0.134,  0.258,  0.414,  0.57 ]])\n",
    "\n",
    "################################\n",
    "\n",
    "X = np.zeros((1, 3))\n",
    "w = np.ones((2,))\n",
    "mu = np.zeros((2, 3))\n",
    "C = np.zeros((2, 3, 3))\n",
    "diag = range(3)\n",
    "C[:, diag, diag] = 1\n",
    "\n",
    "# print(repr(np.round(E_step(X, w, mu, C), 3)))\n",
    "assert np.all(\n",
    "    np.round(E_step(X, w, mu, C), 3) ==\n",
    "    [[ 0.5], [ 0.5]])\n",
    "\n",
    "################################\n",
    "\n",
    "X = np.array([[0,0,0], [1,0,0]])\n",
    "mu = np.array([[0,0,0], [1,0,0]])\n",
    "\n",
    "# print(repr(np.round(E_step(X, w, mu, C), 3)))\n",
    "assert np.all(\n",
    "    np.round(E_step(X, w, mu, C), 3) ==\n",
    "    [[ 0.622,  0.378], [ 0.378,  0.622]])\n",
    "\n",
    "################################\n",
    "\n",
    "gen = np.random.RandomState(seed=123)\n",
    "K, N, D = 4, 1000, 5\n",
    "X = gen.normal(size=(N, D))\n",
    "subsample = X.reshape(K, (N//K), D)\n",
    "mu = subsample.mean(axis=1)\n",
    "C = np.empty((K, D, D))\n",
    "w = gen.uniform(size=K)\n",
    "w /= w.sum()\n",
    "\n",
    "for k in range(K):\n",
    "    C[k] = np.cov(subsample[k], rowvar=False)\n",
    "    \n",
    "#print(repr(np.round(E_step(X, w, mu, C)[:, :5], 3)))\n",
    "assert np.all(\n",
    "    np.round(E_step(X, w, mu, C)[:, :5], 3) ==\n",
    "    [[ 0.422,  0.587,  0.344,  0.279,  0.19 ],\n",
    "     [ 0.234,  0.11 ,  0.269,  0.187,  0.415],\n",
    "     [ 0.291,  0.194,  0.309,  0.414,  0.279],\n",
    "     [ 0.053,  0.109,  0.077,  0.12 ,  0.116]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a6066",
   "metadata": {},
   "source": [
    "**e)** Finalmente, implemente o M-step na função abaixo. Durante esta etapa, consideramos os pesos relativos $p_{nk}$ da etapa anterior fixos e atualizamos os parâmetros de cada componente (que foram corrigidos na etapa anterior), usando:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0ca11",
   "metadata": {},
   "source": [
    "$$\\omega_{k}=\\frac{1}{N}\\sum_{n=1}^{N}p_{nk}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c033c",
   "metadata": {},
   "source": [
    "$$\\overrightarrow{\\mu}_{k}=\\frac{\\sum_{n=1}^{N}p_{nk}\\overrightarrow{x}_{n}}{\\sum_{n=1}^{N}p_{nk}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d356d5",
   "metadata": {},
   "source": [
    "$$C_{k}=\\frac{\\sum_{n=1}^{N}p_{nk}(\\overrightarrow{x}_{n}-\\overrightarrow{\\mu}_{k})(\\overrightarrow{x}_{n}-\\overrightarrow{\\mu}_{k})^{T}}{\\sum_{n=1}^{N}p_{nk}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb8f48",
   "metadata": {},
   "source": [
    "Certifique-se de entender por que a última expressão produz uma matriz em vez de um produto escalar antes de entrar no código. (Se você quiser um desafio Numpy, tente implementar esta função sem nenhum loop, por exemplo, com `np.einsum`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(X, p):\n",
    "    \"\"\"Executa uma etapa M do GMM.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    X : array com shape (N, D)\n",
    "        Dados de entrada consistindo de N amostras em D dimensões.\n",
    "    p : array com shape (K, N)\n",
    "        Array de probabilidades relativas a que cada amostra pertence\n",
    "        cada componente, normalizado para que as probabilidades por componente\n",
    "        para cada soma de amostra para um.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    tuple\n",
    "        Tupla w, mu, C de arrays com shapes (K,), (K, D) e (K, D, D) dando\n",
    "        os parâmetros de componente atualizados.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    K = len(p)\n",
    "    \n",
    "    assert p.shape == (K, N)\n",
    "    assert np.allclose(p.sum(axis=0), 1)\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd84b3",
   "metadata": {},
   "source": [
    "**f)** Aplique os devidos testes de validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-1, 1, 5).reshape(-1, 1)\n",
    "p = np.full(20, 0.25).reshape(4, 5)\n",
    "w, mu, C = M_step(X, p)\n",
    "# print(repr(np.round(w, 5)))\n",
    "# print(repr(np.round(mu, 5)))\n",
    "# print(repr(np.round(C, 5)))\n",
    "\n",
    "assert np.all(np.round(w, 5) == 0.25)\n",
    "assert np.all(np.round(mu, 5) == 0.0)\n",
    "assert np.all(np.round(C, 5) == 0.5)\n",
    "\n",
    "################################\n",
    "\n",
    "gen = np.random.RandomState(seed=123)\n",
    "K, N, D = 4, 1000, 5\n",
    "X = gen.normal(size=(N, D))\n",
    "p = gen.uniform(size=(K, N))\n",
    "p /= p.sum(axis=0)\n",
    "w, mu, C = M_step(X, p)\n",
    "# print(repr(np.round(w, 5)))\n",
    "# print(repr(np.round(mu, 5)))\n",
    "# print(repr(np.round(C[0], 5)))\n",
    "\n",
    "assert np.all(\n",
    "    np.round(w, 5) == [ 0.25216,  0.24961,  0.24595,  0.25229])\n",
    "assert np.all(\n",
    "    np.round(mu, 5) ==\n",
    "    [[ 0.06606,  0.06   , -0.00413,  0.01562,  0.00258],\n",
    "     [ 0.02838,  0.01299,  0.01286,  0.03068, -0.01714],\n",
    "     [ 0.03157,  0.04558, -0.01206,  0.03493, -0.0326 ],\n",
    "     [ 0.05467,  0.06293, -0.01779,  0.04454,  0.00065]])\n",
    "assert np.all(\n",
    "    np.round(C[0], 5) ==\n",
    "    [[ 0.98578,  0.01419, -0.03717,  0.01403,  0.0085 ],\n",
    "     [ 0.01419,  0.95534, -0.02724,  0.03201, -0.00648],\n",
    "     [-0.03717, -0.02724,  0.90722,  0.00313,  0.0299 ],\n",
    "     [ 0.01403,  0.03201,  0.00313,  1.02891,  0.0813 ],\n",
    "     [ 0.0085 , -0.00648,  0.0299 ,  0.0813 ,  0.922  ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9681adf",
   "metadata": {},
   "source": [
    "**g)** Agora você implementou o núcleo do algoritmo GMM. Aqui está um wrapper simples que usa o K-Means para inicializar as probabilidades relativas para que todas sejam zero ou um, com base na atribuição de cluster de cada amostra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd662380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mls import GMM_pairplot\n",
    "\n",
    "def GMM_fit(data, n_components, nsteps, init='random', seed=123):\n",
    "    X = data.values\n",
    "    N, D = X.shape\n",
    "    gen = np.random.RandomState(seed=seed)\n",
    "    p = np.zeros((n_components, N))\n",
    "    if init == 'kmeans':\n",
    "        # Use o KMeans para dividir os dados em clusters.\n",
    "        fit = cluster.KMeans(n_clusters=n_components, random_state=gen).fit(data)\n",
    "        # Inicialize os pesos relativos usando a associação de cluster.\n",
    "        # Os pesos iniciais são, portanto, todos 0 ou 1.\n",
    "        for k in range(n_components):\n",
    "            p[k, fit.labels_ == k] = 1\n",
    "    else:\n",
    "        # Atribua pesos relativos iniciais em quantis do primeiro recurso.\n",
    "        # Esta não é uma boa estratégia de inicialização, mas mostra como\n",
    "        # o GMM converge de um ponto de partida ruim.\n",
    "        x0 = X[:, 0]\n",
    "        edges = np.percentile(x0, np.linspace(0, 100, n_components + 1))\n",
    "        for k in range(n_components):\n",
    "            quantile = (edges[k] <= x0) & (x0 <= edges[k + 1])\n",
    "            p[k, quantile] = 1.\n",
    "            \n",
    "    # Normalize os pesos relativos.\n",
    "    p /= p.sum(axis=0)\n",
    "    # Execute uma etapa M inicial para inicializar os parâmetros do componente.\n",
    "    w, mu, C = M_step(X, p)\n",
    "    # Faça um loop sobre as iterações.\n",
    "    for i in range(nsteps):\n",
    "        p = E_step(X, w, mu, C)\n",
    "        w, mu, C = M_step(X, p)\n",
    "    # Plote os resultados\n",
    "    GMM_pairplot(data, w, mu, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ede322",
   "metadata": {},
   "source": [
    "**h)** Use o 3D no `blobs_data` e mostre que ele converge perto da solução correta após 8 iterações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEU CÓDIGO AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beac1c7",
   "metadata": {},
   "source": [
    "**i)** Mostre que convergência é ainda mais rápida se você usar o KMeans para inicializar os pesos relativos (e é por isso que a maioria das implementações faz isso):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f16610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEU CÓDIGO AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6fcb9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93662d7e",
   "metadata": {},
   "source": [
    "## Problema 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270bc8d",
   "metadata": {},
   "source": [
    "**a)** Um estimador de densidade deve fornecer uma função de densidade de probabilidade $P(\\overrightarrow{x})$ que é normalizada sobre seu espaço de características $\\overrightarrow{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e50b50",
   "metadata": {},
   "source": [
    "$$\\int \\text{d}\\overrightarrow{x}P(\\overrightarrow{x})=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab530e",
   "metadata": {},
   "source": [
    "Neste problema você irá verificar esta normalização para o KDE usando duas abordagens numéricas diferentes para a integral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970e7b8",
   "metadata": {},
   "source": [
    "Primeiro, implemente a função abaixo para aceitar um objeto de ajuste 1D do KDE e estime sua integral de normalização usando a regra do trapézio com a grade especificada. \n",
    "\n",
    "- **Dica**: a função `np.trapz` será útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d619965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grid_normalization(fit, xlo, xhi, ngrid):\n",
    "    \"\"\"Verifique a normalização do resultado de ajuste do estimador de densidade 1D usando a quadratura da grade.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    fit : neighbors.KernelDensity fit object\n",
    "        Resultado do ajuste ao conjunto de dados 1D.\n",
    "    xlo : float\n",
    "        Borda baixa da faixa de integração 1D.\n",
    "    xhi : float\n",
    "        Borda alta da faixa de integração 1D.\n",
    "    ngrid : int\n",
    "        Número de pontos de grade igualmente espaçados cobrindo [xlo, xhi],\n",
    "        incluindo os dois pontos finais.\n",
    "    \"\"\"\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6285ec",
   "metadata": {},
   "source": [
    "**b)** Aplique os *sanity tests* para validar o seu código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7dc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = neighbors.KernelDensity(kernel='gaussian', bandwidth=0.1).fit(blobs_data.drop(columns=['x1', 'x2']))\n",
    "\n",
    "assert np.round(check_mc_normalization(fit, [0], [15], 10), 3) == 1.129\n",
    "assert np.round(check_mc_normalization(fit, [0], [15], 100), 3) == 1.022\n",
    "assert np.round(check_mc_normalization(fit, [0], [15], 1000), 3) == 1.010\n",
    "assert np.round(check_mc_normalization(fit, [0], [15], 10000), 3) == 0.999\n",
    "\n",
    "################################\n",
    "\n",
    "fit = neighbors.KernelDensity(kernel='gaussian', bandwidth=0.1).fit(blobs_data.drop(columns=['x2']))\n",
    "\n",
    "assert np.round(check_mc_normalization(fit, [0, -4], [15, 12], 10), 3) == 1.754\n",
    "assert np.round(check_mc_normalization(fit, [0, -4], [15, 12], 100), 3) == 1.393\n",
    "assert np.round(check_mc_normalization(fit, [0, -4], [15, 12], 1000), 3) == 0.924\n",
    "assert np.round(check_mc_normalization(fit, [0, -4], [15, 12], 10000), 3) == 1.019\n",
    "\n",
    "################################\n",
    "\n",
    "fit = neighbors.KernelDensity(kernel='gaussian', bandwidth=0.1).fit(blobs_data)\n",
    "\n",
    "assert np.round(check_mc_normalization(fit, [0, -4, 2], [15, 12, 18], 10), 3) == 2.797\n",
    "assert np.round(check_mc_normalization(fit, [0, -4, 2], [15, 12, 18], 100), 3) == 0.613\n",
    "assert np.round(check_mc_normalization(fit, [0, -4, 2], [15, 12, 18], 1000), 3) == 1.316\n",
    "assert np.round(check_mc_normalization(fit, [0, -4, 2], [15, 12, 18], 10000), 3) == 1.139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d719343c",
   "metadata": {},
   "source": [
    "**c)** Em seguida, implemente a função abaixo para estimar uma normalização de ajuste multidimensional usando a [integração de Monte Carlo](https://en.wikipedia.org/wiki/Monte_Carlo_integration):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec629d18",
   "metadata": {},
   "source": [
    "$$\\int\\text{d}\\overrightarrow{x}P(\\overrightarrow{x})\\approxeq\\frac{V}{N_{mc}}\\sum_{j=1}^{N_{mc}}P(\\overrightarrow{x}_{j})=V\\langle P\\rangle$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663fd86",
   "metadata": {},
   "source": [
    "onde $\\overrightarrow{x}_{j}$ são distribuídos uniformemente sobre o domínio de integração e $V$ é o volume do domínio de integração. Observe que `trapz` fornece resultados mais precisos para um número fixo de avaliações de $P(\\overrightarrow{x})$, mas a integração MC é muito mais fácil de generalizar para dimensões mais altas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2714a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mc_normalization(fit, xlo, xhi, nmc, seed = 123):\n",
    "    \"\"\"Verifica a normalização do resultado de ajuste do estimador de densidade usando a integração MC.\n",
    "    \n",
    "   Parâmetros\n",
    "    ----------\n",
    "    fit : neighbors.KernelDensity fit object\n",
    "        Resultado do ajuste ao conjunto de dados arbitrário da dimensão D.\n",
    "    xlo : array\n",
    "        1D array de comprimento D com limites baixos de domínio de integração ao longo de cada dimensão.\n",
    "    xhi : array\n",
    "        1D array de comprimento D com altos limites de domínio de integração ao longo de cada dimensão.\n",
    "    nmc : int\n",
    "        Número de pontos de integração MC aleatórios dentro do domínio a ser usado.\n",
    "    \"\"\"\n",
    "    xlo = np.asarray(xlo)\n",
    "    xhi = np.asarray(xhi)\n",
    "    \n",
    "    assert xlo.shape == xhi.shape\n",
    "    assert np.all(xhi > xlo)\n",
    "    \n",
    "    D = len(xlo)\n",
    "    gen = np.random.RandomState(seed=seed)\n",
    "    # Use gen.uniform() em sua solução, não gen.rand(), para obter números aleatórios consistentes.\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f936443",
   "metadata": {},
   "source": [
    "**d)** Por fim, efetue o teste de validação do seu código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d151572",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = neighbors.KernelDensity(kernel='gaussian', bandwidth=0.1).fit(blobs_data.drop(columns=['x1', 'x2']))\n",
    "\n",
    "assert np.round(check_mc_normalization(fit, [0], [15], 10), 3) == 1.129\n",
    "assert np.round(check_mc_normalization(fit, [0], [15], 100), 3) == 1.022\n",
    "assert np.round(check_mc_normalization(fit, [0], [15], 1000), 3) == 1.010\n",
    "assert np.round(check_mc_normalization(fit, [0], [15], 10000), 3) == 0.999\n",
    "\n",
    "################################\n",
    "\n",
    "fit = neighbors.KernelDensity(kernel='gaussian', bandwidth=0.1).fit(blobs_data.drop(columns=['x2']))\n",
    "\n",
    "assert np.round(check_mc_normalization(fit, [0, -4], [15, 12], 10), 3) == 1.754\n",
    "assert np.round(check_mc_normalization(fit, [0, -4], [15, 12], 100), 3) == 1.393\n",
    "assert np.round(check_mc_normalization(fit, [0, -4], [15, 12], 1000), 3) == 0.924\n",
    "assert np.round(check_mc_normalization(fit, [0, -4], [15, 12], 10000), 3) == 1.019\n",
    "\n",
    "################################\n",
    "\n",
    "fit = neighbors.KernelDensity(kernel='gaussian', bandwidth=0.1).fit(blobs_data)\n",
    "\n",
    "assert np.round(check_mc_normalization(fit, [0, -4, 2], [15, 12, 18], 10), 3) == 2.797\n",
    "assert np.round(check_mc_normalization(fit, [0, -4, 2], [15, 12, 18], 100), 3) == 0.613\n",
    "assert np.round(check_mc_normalization(fit, [0, -4, 2], [15, 12, 18], 1000), 3) == 1.316\n",
    "assert np.round(check_mc_normalization(fit, [0, -4, 2], [15, 12, 18], 10000), 3) == 1.139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89509622",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
