{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4966452d",
   "metadata": {},
   "source": [
    "\n",
    "# Uma breve introdução ao Machine Learning\n",
    "## Problemas propostos #04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d297ce5a",
   "metadata": {},
   "source": [
    "- **Dia 4:** [Medição e redução de dimensionalidade.](https://github.com/GabrielWendell/Intro_ML/blob/main/Notebooks/Dia4.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465ab5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eeae97",
   "metadata": {},
   "source": [
    "### Você vai precisar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e73dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mls import locate_data\n",
    "spectra_data = pd.read_hdf(locate_data('spectra_data.hf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5242e621",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02144b41",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c1eea",
   "metadata": {},
   "source": [
    "**a)** O [algoritmo Expectation-Maximization (EM)](https://en.wikipedia.org/wiki/Expectation–maximization_algorithm) é usado para implementar muitos métodos de aprendizado de máquina, incluindo K-means, análise fatorial e PCA ponderado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc1de76",
   "metadata": {},
   "source": [
    "A ideia básica do EM é otimizar uma função objetivo que depende de dois conjuntos disjuntos de parâmetros, atualizando alternadamente um conjunto e depois o outro, usando um esquema que garante a melhoria da função objetivo (embora geralmente para um ótimo local em vez de global. ). As atualizações alternadas são chamadas de E-step e M-step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d3a35",
   "metadata": {},
   "source": [
    "O K-means é um dos usos mais simples do EM, portanto, é uma boa maneira de obter alguma experiência prática."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db05a9",
   "metadata": {},
   "source": [
    "Implemente a função abaixo para executar uma etapa E K-means.\n",
    "\n",
    "- *Dica:* você pode achar o [`np.argmin`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.argmin.html) útil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937da5a",
   "metadata": {},
   "source": [
    "O objetivo deste exercício é escrever uma solução correta, em vez do código mais rápido possível. Portanto, sinta-se à vontade para usar loops sobre índices de matriz, pois geralmente são mais fáceis de entender e acertar do que o código numpy vetorizado equivalente. \n",
    "\n",
    "(Você terá alguma prática escrevendo código vetorizado na próxima pergunta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c588af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(X, centers):\n",
    "    \"\"\"\"Execute um passo E K-means.\"\n",
    "    \n",
    "    Atribua cada amostra ao cluster com o centro mais próximo, usando o\n",
    "    Norma euclidiana para medir a distância entre uma amostra e um centro de cluster.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    X : array com shape (N, D)\n",
    "        Dados de entrada consistindo de N amostras em D dimensões.\n",
    "    centers : array com shape (n, D)\n",
    "        Centros dos n clusters em D dimensões.\n",
    "        \n",
    "    Retorno\n",
    "    -------\n",
    "    integer array com shape (N,)\n",
    "        Índice do cluster de cada sample, no intervalo 0 para n - 1\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    n = len(centers)\n",
    "    \n",
    "    assert centers.shape[1] == D\n",
    "    indexes = np.empty(N, int)\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a3f9f",
   "metadata": {},
   "source": [
    "**b)** Efetue os testes de validação abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = np.random.RandomState(seed=123)\n",
    "X = gen.normal(size=(20, 2))\n",
    "centers = np.array([[0., 0.], [0., 10.]])\n",
    "X[50:] += centers[1]\n",
    "indices = E_step(X, centers)\n",
    "\n",
    "assert np.all(indices[:50] == 0)\n",
    "assert np.all(indices[50:] == 1)\n",
    "\n",
    "centers = gen.uniform(size=(5, 2))\n",
    "indexes = E_step(X, centers)\n",
    "\n",
    "assert np.array_equal(indexes, [4, 1, 4, 4, 1, 0, 1, 0, 2, 1, 2, 4, 0, 1, 0, 1, 0, 1, 4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89113e1",
   "metadata": {},
   "source": [
    "**c)** Implemente a função abaixo para executar uma etapa M de K-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ad549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(X, indexes, n):\n",
    "    \"\"\"Perform a K-means M-step.\n",
    "    \n",
    "    Calcule o centro de cada cluster como a média de suas amostras atribuídas.\n",
    "    \n",
    "    Os centros de quaisquer clusters sem quaisquer amostras atribuídas devem ser definidos para a origem.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    X : array com shape (N, D)\n",
    "        Dados de entrada consistindo de N amostras em D dimensões.\n",
    "        \n",
    "    indexes : integer array com shape (N,)\n",
    "        Índices do cluster de cada sample, no intervalo de 0 até n - 1\n",
    "        \n",
    "    n : int\n",
    "        Number de clusters.  Deve ser <= N.\n",
    "        \n",
    "    Retorno\n",
    "    -------\n",
    "    array com shape (n, D)\n",
    "        Centros dos n clusters em D dimensões.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    assert indices.shape == (N,)\n",
    "    assert n <= N\n",
    "    centers = np.zeros((n, D))\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9655de9d",
   "metadata": {},
   "source": [
    "**d)**  Aplique os *sanity tests* abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2244158",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = np.random.RandomState(seed=123)\n",
    "X = np.ones((20, 2))\n",
    "indices = np.zeros(20, int)\n",
    "centers = M_step(X, indices, 1)\n",
    "\n",
    "assert np.all(centers == 1.)\n",
    "\n",
    "################################\n",
    "\n",
    "n = 5\n",
    "indices = gen.randint(n, size=len(X))\n",
    "centers = M_step(X, indices, n)\n",
    "\n",
    "assert np.all(centers == 1.)\n",
    "\n",
    "################################\n",
    "\n",
    "X = gen.uniform(size=X.shape)\n",
    "centers = M_step(X, indices, n)\n",
    "\n",
    "assert np.allclose(\n",
    "    np.round(centers, 3),\n",
    "    [[ 0.494,  0.381], [ 0.592,  0.645],\n",
    "     [ 0.571,  0.371], [ 0.234,  0.634],\n",
    "     [ 0.250,  0.386]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc739083",
   "metadata": {},
   "source": [
    "**e)** Agora você implementou o núcleo do algoritmo K-means. Experimente com este *wrapper* simples, que faz um gráfico de dispersão das duas primeiras colunas após cada iteração. O wrapper sklearn combina o resultado de vários pontos de partida aleatórios e possui outros refinamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_fit(data, n_clusters, nsteps, seed = 123):\n",
    "    X = data.values\n",
    "    N, D = X.shape\n",
    "    assert n_clusters <= N\n",
    "    gen = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    # Escolha amostras aleatórias como os centros iniciais.\n",
    "    shuffle = gen.permutation(N)\n",
    "    centers = X[shuffle[:n_clusters]]\n",
    "    \n",
    "    # Execute uma etapa E inicial para atribuir amostras a clusters.\n",
    "    indices = E_step(X, centers)\n",
    "    \n",
    "    # Faça um loop sobre as iterações.\n",
    "    for i in range(nsteps):\n",
    "        centers = M_step(X, indices, n_clusters)\n",
    "        indices = E_step(X, centers)\n",
    "        \n",
    "    # Plote o resultado\n",
    "    cmap = np.array(sns.color_palette())\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=cmap[indices % len(cmap)])\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], marker='+', c='k', s=400, lw=5)\n",
    "    opt_plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ca953",
   "metadata": {},
   "source": [
    "**e)** Experimente em alguns dados 2D gerados aleatoriamente com 3 *clusters* separados (usando o prático [make_blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)). Para este teste simples, você deve encontrar uma boa solução após duas iterações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "gen = np.random.RandomState(seed=123)\n",
    "X, _ = make_blobs(500, 2, [[-3,-3],[0,3],[3,-3]], random_state=gen)\n",
    "data = pd.DataFrame(X, columns=('x0', 'x1'))\n",
    "\n",
    "KMeans_fit(data, n_clusters=3, nsteps=0);\n",
    "KMeans_fit(data, n_clusters=3, nsteps=1);\n",
    "KMeans_fit(data, n_clusters=3, nsteps=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051ed88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7827d0ac",
   "metadata": {},
   "source": [
    "## Problema 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ab22f6",
   "metadata": {},
   "source": [
    "**a)** O passo E no problema anterior usa a matriz de separação $S_{ij}$ entre o $0\\leq i<N$ ($D$-dimensional) *samples* $\\textbf{x}_{i}$ e $0\\leq i< n$ ($D$- dimensional) *cluster* significa $\\mu_{j}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e7837",
   "metadata": {},
   "source": [
    "$$S_{ij}\\equiv|\\textbf{x}_{i}-\\mu_{j}|^{2},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b045e",
   "metadata": {},
   "source": [
    "Observe que este é um matriz retangular $N\\times n$, então geralmente não é quadrada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c60e44",
   "metadata": {},
   "source": [
    "Implemente a função abaixo para calcular esta matriz usando `PyTorch`, sem loops explícitos sobre índices de tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9577ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def S_matrix(X, mu):\n",
    "    \"\"\"Calcule a matriz de separação usada pela etapa K-médias E.\n",
    "    \n",
    "    Calcule a matriz 2D S com elementos |x[i] - mu[j]|^2 usando\n",
    "    PyTorch e sem loops explícitos.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    X : torch tensor com shape (N, D)\n",
    "        Dados de entrada consistindo de N amostras em D dimensões.\n",
    "    mu : torch tensor com shape (n, D)\n",
    "        Centros dos n clusters em D dimensões.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    array com shape (N, n)\n",
    "    \"\"\"\n",
    "    N, D = X.size()\n",
    "    n = len(mu)\n",
    "    assert mu.shape[1] == D\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32759d65",
   "metadata": {},
   "source": [
    "**b)** Aplique os seguintes *sanity tests*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dafa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros(5, 3)\n",
    "mu = torch.ones(2, 3)\n",
    "S = S_matrix(X, mu)\n",
    "\n",
    "assert S.size() == (5, 2)\n",
    "assert torch.allclose(S, torch.tensor(3.))\n",
    "\n",
    "################################\n",
    "\n",
    "gen = np.random.RandomState(seed=123)\n",
    "X = torch.tensor(gen.normal(size=(1000, 2)), dtype=torch.float32)\n",
    "mu = torch.tensor([[0., 0.], [0., 10.]])\n",
    "X[50:] += mu[1]\n",
    "S = S_matrix(X, mu)\n",
    "\n",
    "assert S.size() == (1000, 2)\n",
    "assert torch.allclose(torch.mean(S, dim=0), torch.tensor([96.8427, 6.9882]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468a608",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0359af",
   "metadata": {},
   "source": [
    "## Problema 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b6c755",
   "metadata": {},
   "source": [
    "**a)** O método PCA de redução de dimensionalidade primeiro calcula uma decomposição linear exata (até o erro de arredondamento), então apara linhas e colunas para o número desejado de variáveis latentes. Neste problema, você explorará como o PCA é implementado. A complicada álgebra linear já está implementada em [`numpy.linalg`](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.linalg.html), mas ainda é um desafio manter todas as notações e convenções auto consistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75eb5e2",
   "metadata": {},
   "source": [
    "Os dados de entrada $X$ são fornecidos como uma matriz $N\\times D$ (amostras, características). A seguir, assumimos que cada recurso está centrado em zero (caso contrário, calcule e subtraia o $\\mu_{j}$ , depois adicione-os de volta mais tarde),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b0f6d",
   "metadata": {},
   "source": [
    "$$\\mu_{j}=\\sum_{i}X_{ij}=0.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddfa0ae",
   "metadata": {},
   "source": [
    "Existem três métodos equivalentes para realizar a decomposição exata inicial:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b9146",
   "metadata": {},
   "source": [
    "1. Calcular a [matriz de covariância da amostra](https://en.wikipedia.org/wiki/Sample_mean_and_covariance#Sample_covariance) $D\\times D$\n",
    "\n",
    "$$C\\equiv\\frac{1}{N-1}X^{T}X.$$\n",
    "\n",
    "Então encontre sua decomposição de autovalor:\n",
    "\n",
    "$$C=Q^{T}\\Lambda Q$$\n",
    "\n",
    "onde $\\Lambda$ é uma matriz diagonal $D\\times D$ de autovalores e as linhas da matriz ortogonal $D\\times D$ do tipo $Q$ são os autovetores correspondentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717ae4ab",
   "metadata": {},
   "source": [
    "2. Calcule a matriz $N\\times N$ de produtos escalares entre amostras:\n",
    "\n",
    "$$D\\equiv\\frac{1}{N-1}XX^{T},$$\n",
    "\n",
    "então encontre sua decomposição de autovalor, onde agora $Q$ e $\\Lambda$ são matrizes $N\\times N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16efb583",
   "metadata": {},
   "source": [
    "3. Encontre a [decomposição de valor singular (SVD)](https://en.wikipedia.org/wiki/Singular_value_decomposition) de $X$\n",
    "\n",
    "$$X=USV\\implies C=\\frac{1}{N-1}V^{T}S^{2}V$$\n",
    "\n",
    "onde $S$ é uma matriz diagonal $K\\times K$ de valores singulares, $U$ é $N\\times K$ e $V$ é $K\\times D$, com $K=\\min{(N,D)}$. A notação acima é escolhida para corresponder a [`np.linalg.svd`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.svd.html) que você usará abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0f59a",
   "metadata": {},
   "source": [
    "O custo computacional de cada método depende diferentemente dos valores de $N$ e $D$, então o método mais eficiente dependerá da forma dos dados de entrada $X$. Há também considerações numéricas: as matrizes $C$ e $D$ devem ser [definidas positivamente](https://en.wikipedia.org/wiki/Definite_matrix) para garantem autovalores positivos, mas isso não será verdade para $C$ se $N<D$ ou para $D$ se $N>D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7962c9",
   "metadata": {},
   "source": [
    "Implemente a função abaixo para calcular os autovetores e autovalores de uma matriz quadrada de entrada usando uma função adequada de [`np.linalg`](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.linalg.html). Os resultados devem ser classificados em ordem decrescente de autovalores, conforme necessário pelo PCA. \n",
    "\n",
    "- **Dica**: M[::-1] inverte as linhas de um array 2D `M`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1863a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigensolve(M):\n",
    "    \"\"\"Calcular autovetores e autovalores de uma matriz quadrada simétrica.\n",
    "    \n",
    "    Os resultados são classificados por autovalor decrescente. As linhas (não colunas) do\n",
    "    array de autovetores retornados são os autovetores normalizados de M.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    M : 2D array\n",
    "        N x N matriz quadrada simétrica para usar.\n",
    "        \n",
    "    Retorna\n",
    "    -------\n",
    "    tuple\n",
    "        Tupla de matrizes (valores próprios, vetores próprios) com valores próprios decrescentes e\n",
    "        autovetor[i] correspondente ao autovalor[i]. Os valores próprios devem ter o\n",
    "        forma (N,) e vetores próprios devem ter a forma (N, N).\n",
    "    \"\"\"\n",
    "    assert len(M.shape) == 2\n",
    "    nrows, ncols = M.shape\n",
    "    \n",
    "    assert nrows == ncols\n",
    "    assert np.all(M.T == M)\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ccb3a",
   "metadata": {},
   "source": [
    "**b)** Efetue os seguintes testes de validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b969fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.diag(np.arange(1., 5.))\n",
    "evals, evecs = eigensolve(C)\n",
    "\n",
    "assert np.allclose(\n",
    "    evals,\n",
    "    [ 4.,  3.,  2.,  1.])\n",
    "assert np.allclose(\n",
    "    evecs,\n",
    "    [[ 0.,  0.,  0.,  1.],\n",
    "     [ 0.,  0.,  1.,  0.],\n",
    "     [ 0.,  1.,  0.,  0.],\n",
    "     [ 1.,  0.,  0.,  0.]])\n",
    "\n",
    "################################\n",
    "\n",
    "gen = np.random.RandomState(seed=123)\n",
    "N, D = 4, 3\n",
    "X = gen.uniform(size=(N, D))\n",
    "X -= np.mean(X, axis=0)\n",
    "C = np.dot(X.T, X) / (N - 1)\n",
    "evals, evecs = eigensolve(C)\n",
    "\n",
    "assert np.allclose(C, evecs.T.dot(np.diag(evals).dot(evecs)))\n",
    "assert np.allclose(\n",
    "    np.round(evals, 5),\n",
    "    [ 0.08825,  0.0481 ,  0.01983])\n",
    "assert np.allclose(\n",
    "    np.round(evecs, 3),\n",
    "    [[-0.787, -0.477,  0.391],\n",
    "     [-0.117,  0.737,  0.665],\n",
    "     [-0.606,  0.478, -0.636]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a34e3b5",
   "metadata": {},
   "source": [
    "**c)** Implemente a função abaixo para calcular as mesmas quantidades usando o [método SVD](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.svd.html) diretamente em $X$ em vez de resolver o problema de autovalor para a covariância da amostra. \n",
    "\n",
    "- **Dica**: preste atenção no parâmetro `full_matrices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdsolve(X):\n",
    "    \"\"\"Calcule autovetores e autovalores da covariância amostral de X.\n",
    "\n",
    "    Os resultados são classificados por autovalor decrescente. As linhas (não colunas) do\n",
    "    array de autovetores retornados são os autovetores normalizados de M.\n",
    "\n",
    "    Usa o método SVD diretamente no X.\n",
    "    \n",
    "    Parâmetros\n",
    "    ----------\n",
    "    X: 2D array\n",
    "        N x D matriz a ser usada.\n",
    "        \n",
    "    Retorna\n",
    "    -------\n",
    "    tuple\n",
    "        Tupla de matrizes (valores próprios, vetores próprios) com valores próprios decrescentes e\n",
    "        autovetor[i] correspondente ao autovalor[i]. Os valores próprios devem ter o\n",
    "        forma (K,) e autovetores devem ter a forma (K, D) com K = min(N, D).\n",
    "    \"\"\"\n",
    "    assert len(X.shape) == 2\n",
    "    N, D = X.shape\n",
    "    \n",
    "    # SEU CÓDIGO AQUI\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fb1e72",
   "metadata": {},
   "source": [
    "**d)** Efetue os testes de validação abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3833c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = np.random.RandomState(seed=123)\n",
    "N, D = 4, 3\n",
    "X = gen.uniform(size=(N, D))\n",
    "X -= np.mean(X, axis=0)\n",
    "evals, evecs = svdsolve(X)\n",
    "C = np.dot(X.T, X) / (N - 1)\n",
    "\n",
    "assert np.allclose(C, evecs.T.dot(np.diag(evals).dot(evecs)))\n",
    "assert np.allclose(\n",
    "    np.round(evals, 5),\n",
    "    [ 0.08825,  0.0481 ,  0.01983])\n",
    "assert np.allclose(\n",
    "    np.round(evecs, 3),\n",
    "    [[-0.787, -0.477,  0.391],\n",
    "     [ 0.117, -0.737, -0.665],\n",
    "     [ 0.606, -0.478,  0.636]])\n",
    "\n",
    "################################\n",
    "\n",
    "N, D = 3, 4\n",
    "X = gen.uniform(size=(N, D))\n",
    "X -= np.mean(X, axis=0)\n",
    "evals, evecs = svdsolve(X)\n",
    "C = np.dot(X.T, X) / (N - 1)\n",
    "\n",
    "assert np.allclose(C, evecs.T.dot(np.diag(evals).dot(evecs)))\n",
    "assert np.allclose(\n",
    "    np.round(evals, 5),\n",
    "    [ 0.23688,  0.03412,  0.     ])\n",
    "assert np.allclose(\n",
    "    np.round(evecs, 3),\n",
    "    [[ 0.368,  0.874,  0.316, -0.041],\n",
    "     [ 0.752, -0.178, -0.313,  0.553],\n",
    "     [-0.475,  0.445, -0.62 ,  0.439]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e14816",
   "metadata": {},
   "source": [
    "**e)** Observe que os autovetores encontrados pelos dois métodos podem diferir por um sinal geral, mas ambos os conjuntos de autovetores são ortonormais, portanto, igualmente válidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5bd97",
   "metadata": {},
   "source": [
    "O código de driver simples a seguir mostra como construir um ajuste de PCA de suas funções (mas o [driver `sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) tem muito mais opções):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_fit(data, n_components = 2):\n",
    "    X = data.values\n",
    "    N, D = X.shape\n",
    "    print('N,D = {},{}'.format(N, D))\n",
    "    K = min(N, D)\n",
    "    assert n_components <= K\n",
    "    \n",
    "    # Subtraia o valor médio de cada recurso.\n",
    "    mu = np.mean(X, axis=0)\n",
    "    Xc = X - mu\n",
    "    \n",
    "    # Selecione o método baseado em N, D.\n",
    "    if N > 2 * D:\n",
    "        print('Usando o método 1')\n",
    "        evals, M = eigensolve(np.dot(Xc.T, Xc) / (N - 1))\n",
    "        assert evals.shape == (D,) and M.shape == (D, D)\n",
    "    elif D > 2 * N:\n",
    "        print('Usando o méotodo 2')\n",
    "        evals, M = eigensolve(np.dot(Xc, Xc.T) / (N - 1))\n",
    "        assert evals.shape == (N,) and M.shape == (N, N)\n",
    "        # Os autovetores são agora M = U.T do SVD. Converta para M = V.\n",
    "        # Use abs(evals), pois os menores valores podem ser < 0 devido a erros numéricos.\n",
    "        M = np.dot(np.dot(np.diag(np.abs(evals) ** -0.5), M), Xc) / np.sqrt(N - 1)\n",
    "    else:\n",
    "        print('Usando o método 3')\n",
    "        evals, M = svdsolve(Xc)\n",
    "        assert evals.shape == (K,) and M.shape == (K, D)\n",
    "        \n",
    "    # Calcule Y tal que Xc = Y M.\n",
    "    Y = np.dot(Xc, M.T)\n",
    "    \n",
    "    # Aparar para o subespaço de variável latente.\n",
    "    Y = Y[:, :n_components]\n",
    "    M = M[:n_components]\n",
    "    \n",
    "    # Calcular amostras reconstruídas.\n",
    "    Xr = np.dot(Y, M) + mu\n",
    "    \n",
    "    # Plote algumas amostras e suas reconstruções.\n",
    "    for i,c in zip((0, 6, 7), sns.color_palette()):\n",
    "        plt.plot(X[i], '.', c=c, ms=5)\n",
    "        plt.plot(Xr[i], '-', c=c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52bae83",
   "metadata": {},
   "source": [
    "**f)** Teste este driver em cada regime variando o número de recursos usados de spectra_data com $N$, $D = 200, 500$:\n",
    "\n",
    "- $D>>D$: Método 1\n",
    "- $N<<D$: Método 2\n",
    "- $N\\approxeq D$: Método 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_fit(spectra_data.iloc[:, 190:230], n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_fit(spectra_data, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e42a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_fit(spectra_data.iloc[:, 120:320], n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b80abe",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
